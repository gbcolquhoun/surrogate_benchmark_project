{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2cc369b-5c6c-45ca-913d-51d871105093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the FlexiBERT structure to integer vectors\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def encode_json_structure(json_structure, fixed_length=10):\n",
    "    # Define dictionaries to map categories to unique integer IDs\n",
    "    hidden_size_mapping = {128: 0, 256: 1}\n",
    "    operation_type_mapping = {\"SA\": 0, \"LT\": 1, \"DSC\": 2}\n",
    "    num_operation_heads_mapping = {2: 0, 4: 1}\n",
    "    feed_forward_dimension_mapping = {512: 0, 1024: 1}\n",
    "    num_feed_forward_mapping = {1: 0, 3: 1}\n",
    "    SA_mapping = {\"SDP\": 0, \"WMA\": 1}\n",
    "    LT_mapping = {\"DFT\": 0, \"DCT\": 1}\n",
    "    DSC_mapping = {5: 0, 9: 1}\n",
    "\n",
    "    # Encode the JSON structure into numerical representation\n",
    "    encoded_representation = []\n",
    "\n",
    "    # Encode hidden_size\n",
    "    encoded_representation.append(hidden_size_mapping.get(json_structure.get(\"hidden_size\"), -1))\n",
    "\n",
    "    # Encode encoder_layer parameters\n",
    "    layers = 0\n",
    "    for layer in json_structure[\"nas_config\"][\"encoder_layers\"]:\n",
    "        layers = layers + 1\n",
    "        encoded_representation.extend([operation_type_mapping.get(layer[\"operation_type\"], -1),\n",
    "                                      num_operation_heads_mapping.get(layer[\"num_operation_heads\"], -1),\n",
    "                                      feed_forward_dimension_mapping.get(layer[\"feed_forward_dimension\"], -1),\n",
    "                                      num_feed_forward_mapping.get(layer[\"num_feed_forward\"], -1)])\n",
    "\n",
    "        # Encode SA, LT, DSC parameters\n",
    "        if layer[\"operation_type\"] == \"SA\":\n",
    "            encoded_representation.append(SA_mapping.get(layer[\"operation_parameter\"], -1))\n",
    "        elif layer[\"operation_type\"] == \"LT\":\n",
    "            encoded_representation.append(LT_mapping.get(layer[\"operation_parameter\"], -1))\n",
    "        elif layer[\"operation_type\"] == \"DSC\":\n",
    "            encoded_representation.append(DSC_mapping.get(layer[\"operation_parameter\"], -1))\n",
    "    # print(layers)\n",
    "    encoded_representation.insert(0,layers)\n",
    "    # Pad or truncate the encoded representation to the fixed length\n",
    "    if len(encoded_representation) < fixed_length:\n",
    "        encoded_representation.extend([-1] * (fixed_length - len(encoded_representation)))\n",
    "    else:\n",
    "        print(\"MAX SIZE\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Convert the encoded representation to a NumPy array\n",
    "    encoded_representation = np.array(encoded_representation)\n",
    "\n",
    "    return encoded_representation\n",
    "\n",
    "# Example JSON structures\n",
    "json_structure1 = {\n",
    "    \"hidden_size\": 256,\n",
    "    \"nas_config\": {\n",
    "        \"encoder_layers\": [\n",
    "            {'operation_type': 'LT', 'operation_parameter': 'DFT', 'num_operation_heads': 4, 'feed_forward_dimension': 1024, 'num_feed_forward': 3},\n",
    "            {'operation_type': 'SA', 'operation_parameter': 'SDP', 'num_operation_heads': 2, 'feed_forward_dimension': 1024, 'num_feed_forward': 1},\n",
    "            {'operation_type': 'DSC', 'operation_parameter': 9, 'num_operation_heads': 4, 'feed_forward_dimension': 512, 'num_feed_forward': 3},\n",
    "            {'operation_type': 'DSC', 'operation_parameter': 5, 'num_operation_heads': 2, 'feed_forward_dimension': 512, 'num_feed_forward': 1}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "json_structure2 = {\n",
    "    \"hidden_size\": 128,\n",
    "    \"nas_config\": {\n",
    "        \"encoder_layers\": [\n",
    "            {'operation_type': 'SA', 'operation_parameter': 'SDP', 'num_operation_heads': 4, 'feed_forward_dimension': 1024, 'num_feed_forward': 1},\n",
    "            {'operation_type': 'LT', 'operation_parameter': 'DCT', 'num_operation_heads': 2, 'feed_forward_dimension': 1024, 'num_feed_forward': 1},\n",
    "            {'operation_type': 'DSC', 'operation_parameter': 9, 'num_operation_heads': 4, 'feed_forward_dimension': 512, 'num_feed_forward': 3},\n",
    "        ]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f255362-be57-4074-8596-ce84b48db794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  0,  0,  1,  1,  0,  0,  1,  0,  1,  0,  1,  2,  1,  0,  1,  1,\n",
       "       -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_json_structure(json_structure2, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "112aa0c5-e5a5-4ce3-9336-df20f32c7bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved as output.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#READ FLEXIBER ARCH\n",
    "configs = []\n",
    "with open(\"BERT_benchmark.json\", 'r') as f:\n",
    "    configs = json.load(f)\n",
    "\n",
    "\n",
    "data_rows = []\n",
    "accuracy = []\n",
    "latency = []\n",
    "for i in range(500):\n",
    "\n",
    "    nas_config = configs[i][\"hparams\"][\"model_hparam_overrides\"]#[\"nas_config\"]\n",
    "    glue = configs[i][\"scores\"][\"glue\"]#[\"nas_config\"]\n",
    "    latency = (configs[i]['time_to_train'])\n",
    "    #accuracy.append(glue)\n",
    "    json_structure = nas_config\n",
    "    \n",
    "    # Encode the JSON structure into a fixed-size vector representation\n",
    "    fixed_size_vector = encode_json_structure(json_structure, fixed_length=23)\n",
    "    \n",
    "    # Build a row dictionary: add each element of the vector as a separate column.\n",
    "    row = {f\"vector_{j}\": fixed_size_vector[j] for j in range(23)}\n",
    "    row[\"accuracy\"] = glue\n",
    "    row[\"latency\"] = latency / 1000.0\n",
    "\n",
    "    data_rows.append(row)\n",
    "\n",
    "# Create a DataFrame from the data and save it as a CSV file.\n",
    "df = pd.DataFrame(data_rows)\n",
    "df.to_csv(\"output.csv\", index=False)\n",
    "\n",
    "print(\"CSV file saved as output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "202bfdbb-cf22-4538-b600-8df64fe85bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old CSV loaded. Number of rows: 500\n",
      "New CSV loaded. Number of rows: 500\n",
      "Replaced latency column in the new CSV.\n",
      "Updated new CSV saved to: modified_flexibert_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths â€“ update these to the correct paths on your system.\n",
    "old_csv_path = \"old_flexibert_data.csv\"\n",
    "new_csv_path = \"new_flexibert_data.csv\"\n",
    "\n",
    "# Load the old CSV (the one with a single \"vector\" column) into a DataFrame.\n",
    "old_df = pd.read_csv(old_csv_path)\n",
    "print(\"Old CSV loaded. Number of rows:\", len(old_df))\n",
    "\n",
    "# Load the new CSV (the one with separate vector_0, vector_1, ..., columns) into a DataFrame.\n",
    "new_df = pd.read_csv(new_csv_path)\n",
    "print(\"New CSV loaded. Number of rows:\", len(new_df))\n",
    "\n",
    "# Extract the latency column from the old CSV.\n",
    "old_latency = old_df['latency']\n",
    "old_memory = old_df['mem']\n",
    "# Check if the two DataFrames have the same number of rows.\n",
    "if len(old_latency) != len(new_df):\n",
    "    print(\"Warning: Number of rows differ between the old and new CSVs!\")\n",
    "else:\n",
    "    # Replace the 'latency' column in the new DataFrame with the one from the old DataFrame.\n",
    "    new_df['latency'] = old_latency.values\n",
    "    new_df['memory'] = old_memory.values\n",
    "    print(\"Replaced latency column in the new CSV.\")\n",
    "\n",
    "# Optionally, save the updated new DataFrame to a new CSV file.\n",
    "updated_csv_path = \"modified_flexibert_data.csv\"\n",
    "new_df.to_csv(updated_csv_path, index=False)\n",
    "print(\"Updated new CSV saved to:\", updated_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
